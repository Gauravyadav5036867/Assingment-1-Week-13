{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da210b-9601-4dba-b24e-de50b5fd23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "\n",
    "Overfitting : It is a model in which the trained model accuracy is high then we call it low bias high variance.If the trainning accuracy is low then we call it as high bias.\n",
    " Mitigation:\n",
    "            Cross variation, Regularization, feature selection, Early stopping.\n",
    "\n",
    "\n",
    "Underfitting : In the case of underfitting if there is low accuracy then we call it high variance. If the high accuracy occurs then it call low variance.\n",
    "\n",
    "Mitigation:\n",
    "           Increasing model complexity,Adding more features,Reducing regularization,Improving data quality\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08462246-b234-4c18-b8e9-af3a4967648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "\n",
    "We can reduce overfitting using following:\n",
    "    Cross variation, Regularization, feature selection, Early stopping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9cf70-666a-4db5-9721-9201c53ce331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "\n",
    "Underfitting occurs when a machine learning model is too simple to capture the underlying structure of the data. In other words, the model fails to learn from the training data effectively, resulting in poor performance on both the training and test datasets\n",
    "\n",
    "\n",
    "Scenario:\n",
    "    Insufficient model complexity,Limited feature representation,Small training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54624768-b82e-4445-b53a-eea909abd666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "\n",
    "The bias-variance tradeoff is a fundamental concept in machine learning that describes the relationship between the bias of a model and its variance, and how they collectively affect the model's performance\n",
    "\n",
    "1) Bias:\n",
    "    Bias refers to the error introduced by approximating a real-world problem with a simplified model. It represents the difference between the average prediction of the model and the true value being predicted.\n",
    "    \n",
    "2) Variance:\n",
    "    Variance refers to the variability of model predictions for a given data point. It represents the model's sensitivity to fluctuations in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b331cc-183b-4ff9-8ae5-a4d099e811cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5 \n",
    "\n",
    "Detecting overfitting and underfitting in machine learning models is essential for ensuring the model's generalization ability and performance on unseen data. Several common methods can help in identifying these issues:\n",
    "\n",
    "1) Validation curves\n",
    "2) Learning curves\n",
    "3) Cross-validation\n",
    "4) Model evaluation metrics\n",
    "5) Visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5afc24-31cd-4402-b416-3c6eea7d5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6 \n",
    "1) Bias:\n",
    "    Bias refers to the error introduced by approximating a real-world problem with a simplified model.\n",
    "High bias models are overly simplistic and fail to capture the underlying patterns in the data.\n",
    "\n",
    "2) Variance:\n",
    "    Variance refers to the variability of model predictions for a given data point.\n",
    "High variance models are overly complex and capture noise or random fluctuations in the training data.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c346ee-47dd-4382-8421-7b9e0f3a5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7 \n",
    "\n",
    "Regularization is a technique used in machine learning to prevent overfitting by adding a penalty term to the model's objective function. The goal of regularization is to discourage overly complex models that fit the training data too closely, thus improving the model's ability to generalize to unseen data.\n",
    "Common regularization techniques include:\n",
    "    \n",
    "    1) L1 Regularization (Lasso)\n",
    "    2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
